defmodule LazyDoc.Providers.GithubAi do
  @behaviour LazyDoc.Provider

  @github_ai_endpoint "https://models.github.ai/inference/chat/completions"

  ## TO_DO: make timeout,temperature, top_p and max_tokens customizable but with default values.
  ## TO_DO: implement retry with customizable number of retries if fails but with default value.
  @spec request_prompt(binary(), binary(), binary()) ::
          {:ok, Req.Response.t()} | {:error, Exception.t()}
  @doc """
    
  Parameters

  prompt - the input message to be processed by the model.
  model - the identifier for the specific AI model to be used.
  token - the authorization token for accessing the AI service.

  Description
   Sends a prompt to an AI model and returns the generated response.

  Returns
   the response generated by the AI model based on the provided prompt.
  """
  def request_prompt(prompt, model, token) do
    body = %{
      max_tokens: 2048,
      messages: [%{"role" => "system", "content" => ""}, %{"role" => "user", "content" => prompt}],
      model: "#{model}",
      temperature: 1,
      top_p: 1
    }

    Req.Request.new(url: @github_ai_endpoint, options: [json: body, receive_timeout: 240_000])
    |> Req.Request.put_header("Accept", "application/json")
    |> Req.Request.put_header("Content-Type", "application/json;charset=UTF-8")
    |> Req.Request.put_header("Authorization", "Bearer #{token}")
    |> Req.Steps.encode_body()
    |> Req.post()
  end

  ## TO_DO: we should review if for each model in Github you have the same response format in the body.
  ## Maybe this premise is not true and it will require changes.
  @spec get_docs_from_response(Req.Response.t()) :: binary()
  @doc """

  Parameters

  response - a %Req.Response struct containing the response from an HTTP request.
  Description
   Parses the body of the HTTP response and extracts the message content from it.

  Returns
   the content of the message extracted from the response body.

  """
  def get_docs_from_response(%Req.Response{body: body} = _response) do
    map = Jason.decode!(body)
    ## Take always first choice
    message = Enum.at(map["choices"], 0)["message"]["content"]
    message
  end

  @spec model(atom()) :: binary()
  @doc """
   
  Parameters

  model - a symbol representing the model type.
  Description
   Maps the provided model symbol to its corresponding string representation.

  Returns
   the string representation of the specified model.
   
  """
  def model(model) do
    case model do
      :codestral -> "Codestral-2501"
      :gpt_4o -> "gpt-4o"
      :gpt_4o_mini -> "gpt-4o-mini"
    end
  end
end
